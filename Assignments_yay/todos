OUTDATED (see Google doc for any to-do's, notes etc.)










========== TO-DO's =======

MH-8 Q-Learning
- While loop instead of for loop: need convergence criterium
# i think this is fine now. Changed it to a definable constant amount of loops. The
# plot gives a good idea when to terminate.
- cumulative rewards counter

Ask
(1) the range of different alphas and different epsilons we should try for the different algos
(2) How to evaluate the algorithms? ''Typically planning and reinforcement learning algorithms are 
evaluated in terms of quality (e.g., accumulated rewards, error with respect to the 
optimal policy, regret, etc.) as a function of runtime.''
# I've now implemented error w.r.t opt. policy and created a plot for it. This was done
# as a function of loops because this had to do with the question for that MH, but
# of course runtime would also be interesting (implemented by saving t's in a list).

- Based on answers to these questions, adjust Main.py etc. 

Start on other MH's

___

Optimal policy found across different runs: no need right, state value RMSE sufficient (optimal policies are based on state values)
